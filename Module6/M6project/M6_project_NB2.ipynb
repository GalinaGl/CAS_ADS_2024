{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Always activate the environment before running this notebook!\n",
    "#cd /Users/glusker/Documents/courses/CAS_ADS/Module6/M6project\n",
    "#source venv/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprt libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from PIL import Image\n",
    "from IPython.display import display,clear_output\n",
    "from warnings import filterwarnings\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAABlCAYAAACBS66rAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAt5JREFUeJzt279KI1EYxuGTKAriH7SMSWVn4x3YelneqYUBL8AEC8HMMllc2GJ1JnmXw5HnaaYZwseX4seZSSZd13UFAIKmyQ8DgJ64ABAnLgDEiQsAceICQJy4ABAnLgDEHQ65abPZlJeXl3J2dlYmk0l+CgCa0P81crValdlsVqbT6X5x6cOyWCyS8wHQsOVyWebz+X5x6U8svevr6y9Lxd8uLy9rj9Cku7u72iM06eHhofYIzbm9va09QnPW63W5v7//04W94vL5KKwPi7gMd3BwUHuEJh0dHdUeoUknJye1R2jO6elp7RGa9d0rEqUAIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIO5wyE1d122vm80mP8EP9vHxUXuEJr2/v9ceoUlvb2+1R2jOer2uPUKzO/vswr9Muu/uKKU8PT2Vm5ub3HQANG25XJb5fL7fyeXq6mp7fX5+LhcXF7npfrjX19eyWCy2X8L5+XntcZpgZ7uxt/HsbDf9eWS1WpXZbPblfYPiMp3+fjXTh8WXMF6/M3sbx852Y2/j2dl4Qw4ZXugDECcuANSJy/HxcXl8fNxeGc7exrOz3djbeHb2fw36tRgAjOGxGABx4gJAnLgAECcuAMSJCwBx4gJAnLgAECcuAJS0X56zbkrsnucWAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAABlCAYAAACBS66rAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAudJREFUeJzt20FqE3EYxuF/YjRgbQpdSUgWEnBhT+AF6gnU4/SmXTTQA2RMoVoyMqkoCupM8sow8jybyWIIH98sfsxMMqrrui4AEDROfhkANMQFgDhxASBOXACIExcA4sQFgDhxASBu0uak3W5Xbm9vy+npaRmNRvkpABiE5q+RVVWV+XxexuPxcXFpwrJcLpPzATBg6/W6LBaL4+LS3LHsvX1ZysSTtLYuL173PcIgTZ7v+h5hkFaXr/oeYXA+vvnQ9wiDs63uyruL9z+6cExcvj8Km4zLSFxaezpttV5+MZmKyyGmJ8/6HmFwXsxO+h5hsP72ikQpAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIibtDmpruvHDw+78u0TLXy5f+h7hEGqn+z6HmGQ7ref+x5hcD5ttn2PMDjb6u7nLvzGqP7bGaWU6+vrslqtctMBMGjr9bosFovj7lzOz8/3x5ubm3J2dpab7j+32WzKcrncX4TZbNb3OINgZ4ext+7s7DDN/UhVVWU+n//xvFZxGY8fX800YXERumt2Zm/d2Nlh7K07O+uuzU2GF/oAxIkLAP3EZTqdlqurq/2R9uytOzs7jL11Z2f/VqtfiwFAFx6LARAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQEn7CirQb1VcZnLjAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAABlCAYAAACBS66rAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAAudJREFUeJzt28FKG2EYhtE/iSJKoxLoJiSrrLtoN+57IeKdeKcuDHgBmZIuxEyZtBa6qM4kbxmmnLOZzSAfXyIPfyYZ1XVdFwAIGif/GAA0xAWAOHEBIE5cAIgTFwDixAWAOHEBIO6kzU273a48PT2V6XRaRqNRfgoABqH5aWRVVWU+n5fxeHxcXJqwLJfL5HwADNh6vS6LxeK4uDQnlsan6+sycXJpbTWb9T3CIH3dbPoeYZC+3Nz0PcLgfLy97XuEwam22/L57u53F46Ky+tHYU1YJm8cg/jT6WTS9wiDdO49dpAPp6d9jzA404uLvkcYrPcekfgvBiBOXACIExcA4sQFgDhxASBOXACIExcA4sQFgDhxASBOXACIExcA4sQFgDhxASBOXACIExcA4sQFgDhxASBOXACIExcA4sQFgDhxASBOXACIExcA4sQFgDhxASBOXACIExcA4sQFgDhxASBOXACIExcA4sQFgDhxASBOXACIExcA4sQFgDhxASBOXACIExcA4sQFgDhxASBOXACIExcA4sQFgDhxASBOXACIExcA4sQFgDhxASBOXACIExcA4sQFgDhxASBOXACIExcA4sQFgDhxASBOXACIExcA4sQFgDhxASBOXACIExcA4sQFgDhxASBOXACIExcA4sQFgDhxASBOXACIExcA4sQFgDhxASDupM1NdV3vry/NdbfLT/Gfen556XuEQfruPXaQb8/PfY8wOOfbbd8jDE71a2evXfibUf3eHaWUh4eHslqtctMBMGjr9bosFovjTi6z2Wx/fXx8LFdXV7np/nObzaYsl8v9i3B5edn3OINgZ4ext+7s7DDNeaSqqjKfz9+8r1VcxuOfj2aasHgRumt2Zm/d2Nlh7K07O+uuzSHDA30A4sQFgH7icnZ2Vu7v7/dX2rO37uzsMPbWnZ39W62+LQYAXfhYDIA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAEraD3SgcWDm+3DHAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Color definition for images\n",
    "colors_dark = [\"#1F1F1F\", \"#313131\", '#636363', '#AEAEAE', '#DADADA']\n",
    "colors_red = [\"#331313\", \"#582626\", '#9E1717', '#D35151', '#E9B4B4']\n",
    "colors_green = ['#01411C','#4B6F44','#4F7942','#74C365','#D0F0C0']\n",
    "\n",
    "sns.palplot(colors_dark)\n",
    "sns.palplot(colors_green)\n",
    "sns.palplot(colors_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Introducing labels in the dataset\n",
    "\n",
    "dataset_path = \"/Users/glusker/Documents/courses/CAS_ADS/Module6/M6project/Training\"\n",
    "labels = ['glioma_tumor', 'no_tumor', 'meningioma_tumor', 'pituitary_tumor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading glioma_tumor: 100%|██████████| 826/826 [00:00<00:00, 1063.86it/s]\n",
      "Loading no_tumor: 100%|██████████| 395/395 [00:00<00:00, 1299.73it/s]\n",
      "Loading meningioma_tumor: 100%|██████████| 822/822 [00:00<00:00, 1230.23it/s]\n",
      "Loading pituitary_tumor: 100%|██████████| 827/827 [00:00<00:00, 997.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2870 images from the Training dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading no_tumor_augmented: 100%|██████████| 425/425 [00:00<00:00, 3557.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset size after merging no_tumor: 3295 images\n",
      "Class distribution before augmentation:\n",
      "glioma_tumor: 826 images\n",
      "no_tumor: 820 images\n",
      "meningioma_tumor: 822 images\n",
      "pituitary_tumor: 827 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Paths\n",
    "train_dir = \"/Users/glusker/Documents/courses/CAS_ADS/Module6/M6project/Training\"\n",
    "augmented_no_tumor_dir = \"/Users/glusker/Documents/courses/CAS_ADS/Module6/M6project/Training/no_tumor_augmented\"\n",
    "\n",
    "# Initialize lists\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Load original images\n",
    "labels = [\"glioma_tumor\", \"no_tumor\", \"meningioma_tumor\", \"pituitary_tumor\"]\n",
    "for label in labels:\n",
    "    folder_path = os.path.join(train_dir, label)\n",
    "    for filename in tqdm(os.listdir(folder_path), desc=f\"Loading {label}\"):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            X_train.append(img)\n",
    "            y_train.append(label)\n",
    "\n",
    "# Convert to NumPy arrays but keep lists to avoid dimension issues\n",
    "X_train = np.array(X_train, dtype=object)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(f\"Loaded {X_train.shape[0]} images from the Training dataset.\")\n",
    "\n",
    "# Load and merge No Tumor Augmented Images\n",
    "if os.path.exists(augmented_no_tumor_dir):\n",
    "    for filename in tqdm(os.listdir(augmented_no_tumor_dir), desc=\"Loading no_tumor_augmented\"):\n",
    "        img_path = os.path.join(augmented_no_tumor_dir, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            X_train = list(X_train)  # Ensure X_train is a list\n",
    "            X_train.append(img)\n",
    "            y_train = np.append(y_train, \"no_tumor\")\n",
    "\n",
    "# Convert X_train back to NumPy array\n",
    "X_train = np.array(X_train, dtype=object)\n",
    "\n",
    "# Count class distribution\n",
    "class_counts = Counter(y_train)\n",
    "\n",
    "print(f\"Final dataset size after merging no_tumor: {X_train.shape[0]} images\")\n",
    "print(\"Class distribution before augmentation:\")\n",
    "for label, count in class_counts.items():\n",
    "    print(f\"{label}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading glioma_tumor: 100%|██████████| 826/826 [00:00<00:00, 961.58it/s] \n",
      "Loading no_tumor: 100%|██████████| 395/395 [00:00<00:00, 1309.83it/s]\n",
      "Loading meningioma_tumor: 100%|██████████| 822/822 [00:00<00:00, 1191.82it/s]\n",
      "Loading pituitary_tumor: 100%|██████████| 827/827 [00:00<00:00, 1026.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2870 images from the Training dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging no_tumor_augmented: 100%|██████████| 425/425 [00:00<00:00, 4436.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset size after merging no_tumor: 3295 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Paths\n",
    "train_dir = \"/Users/glusker/Documents/courses/CAS_ADS/Module6/M6project/Training\"\n",
    "augmented_dir = \"/Users/glusker/Documents/courses/CAS_ADS/Module6/M6project/Training/no_tumor_augmented\"\n",
    "\n",
    "# Initialize lists\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Load original images\n",
    "labels = [\"glioma_tumor\", \"no_tumor\", \"meningioma_tumor\", \"pituitary_tumor\"]\n",
    "for label in labels:\n",
    "    folder_path = os.path.join(train_dir, label)\n",
    "    for filename in tqdm(os.listdir(folder_path), desc=f\"Loading {label}\"):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            X_train.append(img)\n",
    "            y_train.append(label)\n",
    "\n",
    "# Convert to NumPy arrays but **keep lists to avoid dimension issues**\n",
    "X_train = np.array(X_train, dtype=object)  \n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(f\"Loaded {X_train.shape[0]} images from the Training dataset.\")\n",
    "\n",
    "# Load No Tumor Augmented Images and MERGE them with `no_tumor`\n",
    "merged_no_tumor_images = []\n",
    "merged_no_tumor_labels = []\n",
    "\n",
    "if os.path.exists(augmented_dir):\n",
    "    for filename in tqdm(os.listdir(augmented_dir), desc=\"Merging no_tumor_augmented\"):\n",
    "        img_path = os.path.join(augmented_dir, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            merged_no_tumor_images.append(img)  \n",
    "            merged_no_tumor_labels.append(\"no_tumor\")\n",
    "\n",
    "# Append merged no_tumor dataset\n",
    "if len(merged_no_tumor_images) > 0:\n",
    "    X_train = list(X_train)  \n",
    "    X_train.extend(merged_no_tumor_images)  \n",
    "    y_train = np.concatenate((y_train, np.array(merged_no_tumor_labels)), axis=0)\n",
    "\n",
    "print(f\"Final dataset size after merging no_tumor: {len(X_train)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before augmentation:\n",
      "glioma_tumor: 826 images\n",
      "no_tumor: 820 images\n",
      "meningioma_tumor: 822 images\n",
      "pituitary_tumor: 827 images\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count current images before augmentation\n",
    "class_counts = Counter(y_train)\n",
    "\n",
    "print(\"Class distribution before augmentation:\")\n",
    "for label, count in class_counts.items():\n",
    "    print(f\"{label}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, contrast-focused augmentation is the priority, especially for \"no_tumor\" vs \"meningioma\", since they are visually similar.\n",
    "\n",
    "Plan for Augmentation:\n",
    "For \"no_tumor\" (Heavy Augmentation)\n",
    "\n",
    "Contrast adjustment (CLAHE)\n",
    "Brightness shifts\n",
    "Horizontal & vertical flips\n",
    "Rotation (±15°)\n",
    "Zoom (random crop)\n",
    "Add Gaussian noise\n",
    "For Other Classes (Light Augmentation)\n",
    "\n",
    "Small rotations (±10°)\n",
    "Horizontal flips\n",
    "Slight brightness adjustments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
